@online{MetricsArticle,
    author = {Niaz, Faizan},
    title = {Understanding Evaluation Metrics in Machine Learning: R-Squared is a Pain!},
    year = {2022},
    url = {https://www.linkedin.com/pulse/understanding-evaluation-metrics-machine-learning-r-squared-pain},
    note = {LinkedIn article},
    urldate = {2024-06-02}
}

@INPROCEEDINGS{NasaEngine,
  author={Saxena, Abhinav and Goebel, Kai and Simon, Don and Eklund, Neil},
  booktitle={2008 International Conference on Prognostics and Health Management}, 
  title={Damage propagation modeling for aircraft engine run-to-failure simulation}, 
  year={2008},
  volume={},
  number={},
  pages={1-9},
  keywords={Aircraft propulsion;Prognostics and health management;Engines;NASA;Life estimation;Turbines;Response surface methodology;Thermal sensors;Time measurement;Space vehicles;Damage modeling;Prognostics;C-MAPSS;Turbofan engines;Performance Evaluation},
  doi={10.1109/PHM.2008.4711414}}

@misc{Alhamaly,
  author = {Ali Alhamaly},
  title = {Jet Engine Remaining Useful Life (RUL) Prediction},
  year = {2022},
  url = {https://medium.com/@hamalyas_/jet-engine-remaining-useful-life-rul-prediction-a8989d52f194},
  note = {Accessed: 2024-05-28}
}

@article{ThakkarUnnati2022,
author = {Thakkar, Unnati and Chaoui, Hicham},
year = {2022},
month = {02},
pages = {67},
title = {Remaining Useful Life Prediction of an Aircraft Turbofan Engine Using Deep Layer Recurrent Neural Networks},
volume = {11},
journal = {Actuators},
doi = {10.3390/act11030067}
}

@article{E2023,
  author = {Kıymet Ensarioğlu and Tülin İnkaya and Erdal Emel},
  title = {Remaining Useful Life Estimation of Turbofan Engines with Deep Learning Using Change-Point Detection Based Labeling and Feature Engineering},
  journal = {Applied Sciences},
  year = {2023},
  volume = {13},
  number = {21},
  pages = {11893},
  doi = {10.3390/app132111893}
}

@article{faa2022,
  title={In-Flight Emergencies Statistics},
  author={{Federal Aviation Administration (FAA)}},
  journal={FAA Safety Briefing},
  year={2022}
}

@book{iata2021,
  title={Economic Performance of the Airline Industry},
  author={{International Air Transport Association (IATA)}},
  year={2021},
  publisher={IATA Annual Review}
}

@conference{iata2023,
  title={Benefits of Predictive Maintenance in Aviation},
  author={{International Air Transport Association (IATA)}},
  booktitle={IATA Maintenance Cost Conference},
  year={2023}
}
@article{Solis-Martin,
    author = {Solis-Martin D., Galán-Páez J., & Borrego-Diaz J.},
    title = {A stacked deep convolutional neural network to predict the remaining useful life of a turbofan engine.},
    journal = { arXiv preprint arXiv:2111.12689.},
    year = {2021} 
}

@article{Breiman2001,
  title={Random Forests},
  author={Breiman, Leo},
  journal={Machine Learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer},
  doi={10.1023/A:1010933404324},
  url={https://doi.org/10.1023/A:1010933404324},
  issn={1573-0565},
  abstract={Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.}
}

@article{Biau2016,
    author = {Biau, Gérard and Scornet, Erwan},
    title = {A random forest guided tour},
    journal = {TEST},
    volume = {25},
    number = {2},
    pages = {197--227},
    year = {2016},
    doi = {10.1007/s11749-016-0481-7},
    url = {https://doi.org/10.1007/s11749-016-0481-7},
    issn = {1863-8260},
    abstract = {The random forest algorithm, proposed by L. Breiman in 2001, has been extremely successful as a general-purpose classification and regression method. The approach, which combines several randomized decision trees and aggregates their predictions by averaging, has shown excellent performance in settings where the number of variables is much larger than the number of observations. Moreover, it is versatile enough to be applied to large-scale problems, is easily adapted to various ad hoc learning tasks, and returns measures of variable importance. The present article reviews the most recent theoretical and methodological developments for random forests. Emphasis is placed on the mathematical forces driving the algorithm, with special attention given to the selection of parameters, the resampling mechanism, and variable importance measures. This review is intended to provide non-experts easy access to the main ideas.}
}

@article{liaw2002classification,
  title={Classification and regression by randomForest},
  author={Liaw, Andy and Wiener, Matthew and others},
  journal={R news},
  volume={2},
  number={3},
  pages={18--22},
  year={2002}
}

@Inbook{Awad2015,
author="Awad, Mariette
and Khanna, Rahul",
title="Support Vector Regression",
bookTitle="Efficient Learning Machines: Theories, Concepts, and Applications for Engineers and System Designers",
year="2015",
publisher="Apress",
address="Berkeley, CA",
pages="67--80",
abstract="Rooted in statistical learning or Vapnik-Chervonenkis (VC) theory, support vector machines (SVMs) are well positioned to generalize on yet-to-be-seen data. The SVM concepts presented in Chapter 3can be generalized to become applicable to regression problems. As in classification, support vector regression (SVR) is characterized by the use of kernels, sparse solution, and VC control of the margin and the number of support vectors. Although less popular than SVM, SVR has been proven to be an effective tool in real-value function estimation. As a supervised-learning approach, SVR trains using a symmetrical loss function, which equally penalizes high and low misestimates. Using Vapnik's -insensitive approach, a flexible tube of minimal radius is formed symmetrically around the estimated function, such that the absolute values of errors less than a certain threshold are ignored both above and below the estimate. In this manner, points outside the tube are penalized, but those within the tube, either above or below the function, receive no penalty. One of the main advantages of SVR is that its computational complexity does not depend on the dimensionality of the input space. Additionally, it has excellent generalization capability, with high prediction accuracy.",
isbn="978-1-4302-5990-9",
doi="10.1007/978-1-4302-5990-9_4",
url="https://doi.org/10.1007/978-1-4302-5990-9_4"
}

@misc{dataflair_svm_kernel,
  title   = {Kernel Functions - Introduction to SVM Kernel & Examples},
  author  = {DataFlair Team},
  year    = {2017},
  url     = {https://data-flair.training/blogs/svm-kernel-functions/},
  note    = "[Blog post]",
  accessdate = {2024-06-02}
}

@article{friedman2010regularization,
  title={Regularization Paths for Generalized Linear Models via Coordinate Descent},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  journal={Journal of Statistical Software},
  volume={33},
  number={1},
  pages={1--22},
  year={2010}
}

@article{zou2005regularization,
  title={Regularization and Variable Selection via the Elastic Net},
  author={Zou, Hui and Hastie, Trevor},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={67},
  number={2},
  pages={301--320},
  year={2005},
  publisher={Wiley Online Library}
}

@book{gujarati2019linear,
  title = {Linear Regression: A Mathematical Introduction},
  author = {Gujarati, Damodar N.},
  year = {2019},
  publisher = {SAGE Publications, Inc},
  isbn = {9781071802571},
  url = {https://methods.sagepub.com/book/linear-regression},
  abstract = {},
  chapter = {pages 1-21},
  series = {Sage Research Methods},
  location = {Thousand Oaks, California},
  urldate = {2024-06-02}
}

@book{breiman1984classification,
  title={Classification and Regression Trees},
  author={Breiman, Leo and Friedman, Jerome H and Olshen, Richard A and Stone, Charles J},
  year={1984},
  publisher={Wadsworth International Group}
}

@manual{scikit-learn,
  author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Penvén, Pierre and Vanderplas, Jake and Weiss, Robert and others},
  title = {scikit-learn: Machine Learning in Python},
  year = {2011},
  url = {https://scikit-learn.org/stable/},
}

@manual{pandas,
  title = {pandas: User Guide},
  author = {McKinney, Wes},
  year = {2010},
  organization = {PyData},
  url = {https://pandas.pydata.org/docs/user_guide/index.html},
}

@manual{numpy,
  title = {NumPy User Guide},
  author = {NumPy Developers},
  year = {2024},
  organization = {NumPy Project},
  url = {https://numpy.org/doc/stable/user/index.html},
}

@manual{seaborn,
  title = {seaborn: statistical data visualization},
  author = {Seaborn developers},
  year = {2024}, 
  organization = {PyData},
  url = {https://seaborn.pydata.org/},
}

@manual{matplotlib,
  title = {Matplotlib: User Guide},
  author = {Matplotlib developers}, 
  year = {2024}, 
  organization = {Matplotlib project},
  url = {https://matplotlib.org/stable/users/index.html},
}

@article{wei2018study,
  title={Study on vibration characteristics of fan shaft of geared turbofan engine with sudden imbalance caused by blade off},
  author={Wei, Jing and Bai, Peixin and Qin, DaTong and Lim, Teik C and Yang, PanWu and Zhang, Hong},
  journal={Journal of Vibration and Acoustics},
  volume={140},
  number={4},
  pages={041010},
  year={2018},
  publisher={American Society of Mechanical Engineers}
}